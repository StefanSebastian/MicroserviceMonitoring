@inproceedings{msc,
author = {Jindal, Anshul and Podolskiy, Vladimir and Gerndt, Michael},
year = {2019},
month = {04},
pages = {25-32},
title = {Performance Modeling for Cloud Microservice Applications},
doi = {10.1145/3297663.3310309}
}
@MISC{scryer,
   author =       {Daniel Jacobson, Danny Yuan, Neeraj Joshi},
   title =        {Scryer: Netflix’s Predictive Auto Scaling Engine},
   editor =       {Netflix Technology Blog},
   month =        {November},
   year =         {2013},
   url = {https://netflixtechblog.com/scryer-netflixs-predictive-auto-scaling-engine-a3f8fc922270},
   note =         {[Online; posted 05-November-2013]},
 }
 @Article{wikidata,
  author = 	 {Urdaneta, Guido and Pierre, Guillaume and van Steen, Maarten},
  title = 	 {Wikipedia Workload Analysis for Decentralized Hosting},
  volume =       {53},
  number =       {11},
  pages =        {1830-1845},
  month =        {July},
  year = 	 {2009},
  journal = 	 {Elsevier Computer Networks},
  note = 	 {\url{http://www.globule.org/publi/WWADH_comnet2009.html}}
}
@INPROCEEDINGS{CloudInsight, 
author={I. K. {Kim} and W. {Wang} and Y. {Qi} and M. {Humphrey}}, 
booktitle={2018 IEEE 11th International Conference on Cloud Computing (CLOUD)}, 
title={CloudInsight: Utilizing a Council of Experts to Predict Future Cloud Application Workloads}, 
year={2018}, 
volume={}, 
number={}, 
pages={41-48},
}
@Inbook{sliding_window,
author="Bontempi, Gianluca
and Ben Taieb, Souhaib
and Le Borgne, Yann-A{\"e}l",
editor="Aufaure, Marie-Aude
and Zim{\'a}nyi, Esteban",
title="Machine Learning Strategies for Time Series Forecasting",
bookTitle="Business Intelligence: Second European Summer School, eBISS 2012, Brussels, Belgium, July 15-21, 2012, Tutorial Lectures",
year="2013",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="62--77",
abstract="The increasing availability of large amounts of historical data and the need of performing accurate forecasting of future behavior in several scientific and applied domains demands the definition of robust and efficient techniques able to infer from observations the stochastic dependency between past and future. The forecasting domain has been influenced, from the 1960s on, by linear statistical methods such as ARIMA models. More recently, machine learning models have drawn attention and have established themselves as serious contenders to classical statistical models in the forecasting community. This chapter presents an overview of machine learning techniques in time series forecasting by focusing on three aspects: the formalization of one-step forecasting problems as supervised learning tasks, the discussion of local learning techniques as an effective tool for dealing with temporal data and the role of the forecasting strategy when we move from one-step to multiple-step forecasting.",
isbn="978-3-642-36318-4",
doi="10.1007/978-3-642-36318-4_3",
url="https://doi.org/10.1007/978-3-642-36318-4_3"
}
@book{kfold,
author = {Russell, Stuart and Norvig, Peter},
title = {Artificial Intelligence: A Modern Approach},
year = {2009},
isbn = {0136042597},
publisher = {Prentice Hall Press},
address = {USA},
edition = {3rd}
}
@article{arima,
author = {Ho, S. L. and Xie, M.},
title = {The Use of ARIMA Models for Reliability Forecasting and Analysis},
year = {1998},
issue_date = {October 1998},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {35},
number = {1–2},
issn = {0360-8352},
url = {https://doi.org/10.1016/S0360-8352(98)00066-7},
doi = {10.1016/S0360-8352(98)00066-7},
journal = {Comput. Ind. Eng.},
month = oct,
pages = {213–216},
numpages = {4},
}
@article{Dickey-Fuller,
  title={Lag order and critical values of the augmented Dickey--Fuller test},
  author={Cheung, Yin-Wong and Lai, Kon S},
  journal={Journal of Business \& Economic Statistics},
  volume={13},
  number={3},
  pages={277--280},
  year={1995},
  publisher={Taylor \& Francis Group}
}
@article{batch_size,
author = {Keskar, Nitish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping},
year = {2016},
month = {09},
pages = {},
title = {On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima}
}
@article{dropout,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  number  = {56},
  pages   = {1929-1958},
  url     = {http://jmlr.org/papers/v15/srivastava14a.html}
}
@article{cnn,
author = {LeCun, Yann and Bengio, Y. and Hinton, Geoffrey},
year = {2015},
month = {05},
pages = {436-44},
title = {Deep Learning},
volume = {521},
journal = {Nature},
doi = {10.1038/nature14539}
}
@article{cnn_lstm,
      title = {Hybrid Neural Networks for Learning the Trend in Time  Series},
      author = {Lin, Tao and Guo, Tian and Aberer, Karl},
      pages = {2273-2279},
      year = {2017},
      abstract = {The trend of time series characterizes the intermediate  upward and downward behaviour of time series. Learning and  forecasting the trend in time series data play an important  role in many real applications, ranging from resource  allocation in data centers, load schedule in smart grid,  and so on. Inspired by the recent successes of neural  networks, in this paper we propose TreNet, a novel  end-to-end hybrid neural network to learn local and global  contextual features for predicting the trend of time  series. TreNet leverages convolutional neural networks  (CNNs) to extract salient features from local raw data of  time series. Meanwhile, considering the long-range  dependency existing in the sequence of historical trends of  time series, TreNet uses a long-short term memory recurrent  neural network (LSTM) to capture such dependency. Then, a  feature fusion layer is to learn joint representation for  predicting the trend. TreNet demonstrates its effectiveness  by outperforming CNN, LSTM, the cascade of CNN and LSTM,  Hidden Markov Model based method and various kernel based  baselines on real datasets.},
      url = {http://infoscience.epfl.ch/record/262447},
      doi = {10.24963/ijcai.2017/316},
}
@article{ann_prediction,
title = "Workload prediction in cloud using artificial neural network and adaptive differential evolution",
journal = "Future Generation Computer Systems",
volume = "81",
pages = "41 - 52",
year = "2018",
issn = "0167-739X",
doi = "https://doi.org/10.1016/j.future.2017.10.047",
url = "http://www.sciencedirect.com/science/article/pii/S0167739X17300444",
author = "Jitendra Kumar and Ashutosh Kumar Singh",
keywords = "Cloud computing, Data center, Workload prediction, Neural network, Differential evolution",
abstract = "Cloud computing has drastically transformed the means of computing in recent years. In spite of numerous benefits, it suffers from some challenges too. Major challenges of cloud computing include dynamic resource scaling and power consumption. These factors lead a cloud system to become inefficient and costly. The workload prediction is one of the variables by which the efficiency and operational cost of a cloud can be improved. Accuracy is the key component in workload prediction and the existing approaches lag in producing 100% accurate results. The researchers are also putting their consistent efforts for its improvement. In this paper, we present a workload prediction model using neural network and self adaptive differential evolution algorithm. The model is capable of learning the best suitable mutation strategy along with optimal crossover rate. The experiments were performed on the benchmark data sets of NASA and Saskatchewan servers’ HTTP traces for different prediction intervals. We compared the results with prediction model based on well known back propagation learning algorithm and received significant improvement. The proposed model attained a shift up to 168 times in the error reduction and prediction error is reduced up to 0.001."
}
@ARTICLE{arima_prediction,  
author={R. N. {Calheiros} and E. {Masoumi} and R. {Ranjan} and R. {Buyya}},  
journal={IEEE Transactions on Cloud Computing},  
title={Workload Prediction Using ARIMA Model and Its Impact on Cloud Applications’ QoS},   
year={2015},  
volume={3},  
number={4},  
pages={449-458},
}
@INPROCEEDINGS{brown_prediction,  
author={H. {Mi} and H. {Wang} and G. {Yin} and Y. {Zhou} and D. {Shi} and L. {Yuan}},  
booktitle={2010 IEEE International Conference on Services Computing},  
title={Online Self-Reconfiguration with Performance Guarantee for Energy-Efficient Large-Scale Cloud Computing Data Centers},   year={2010},  volume={},  number={},  pages={514-521},}
